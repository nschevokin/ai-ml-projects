{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPFPtHankgU8"
      },
      "source": [
        "# Project Description:\n",
        "\n",
        "The purpose of this project is to implement a neural network that performs the translation of mathematical formulae from traditional **infix notation**—where the operator appears between two operands—to **postfix** (also known as Reverse Polish Notation), where the operator follows the operands.\n",
        "\n",
        "Infix notation is the most commonly used in human-readable mathematics (e.g., a + b), but it is inherently ambiguous without additional syntactic aids such as parentheses or operator precedence rules. This ambiguity arises because different parse trees can correspond to the same expression depending on how operations are grouped.\n",
        "\n",
        "In contrast, postfix notation eliminates the need for parentheses entirely. The order of operations is explicitly encoded by the position of the operators relative to the operands, making it more suitable for stack-based evaluation and easier to parse programmatically.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Consider the ambiguous infix expression:\n",
        "a + b * c\n",
        "\n",
        "This expression can be parsed in at least two different ways:\n",
        "\n",
        "Interpretation (Infix):\t(a + b) * c\t   \n",
        "Equivalent Postfix: ab+c*\n",
        "\n",
        "Interpretation (Infix):\ta + (b * c)\t          \n",
        "Equivalent Postfix: abc*+\n",
        "\n",
        "\n",
        "This project aims to learn such disambiguations and generate the correct postfix form from a given infix expression using a data-driven approach based on neural networks. To simplify the task and control the complexity of expressions, we restrict our dataset to formulae with a maximum syntactic depth of 3. This means that the abstract syntax trees representing these expressions will have at most three levels, ensuring that the neural network operates on a bounded and manageable set of possible structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_tRkF6n6smU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import random\n",
        "import string\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import Model, regularizers\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFSHpEHjpa1x"
      },
      "source": [
        "We build formulae using 5 identifiers a,b,c,d,e and 4 binary operators +,-,*,/.\n",
        "For simplicity we do not take advantage of precedence or associativity rules for infix notation, and suppose that all binary operations as always fully parenthesizes: (e1 op e2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IINM81OK61pH"
      },
      "outputs": [],
      "source": [
        "# -------------------- Constants --------------------\n",
        "OPERATORS = ['+', '-', '*', '/'] # a list of 4 binary operators we support\n",
        "IDENTIFIERS = list('abcde') # the 5 variable names used as so-callled leaf nodes in generated expression trees\n",
        "SPECIAL_TOKENS = ['PAD', 'SOS', 'EOS'] # PAD - used to pad every sequence to a fixed length (seemingly, for batching), SOS - start of sequence, EOS - end of sequence\n",
        "SYMBOLS = ['(', ')', '+', '-', '*', '/'] # parentheses themselves in the vocabulary, since infix expressions are fully parenthesized\n",
        "VOCAB = SPECIAL_TOKENS + SYMBOLS + IDENTIFIERS + ['JUNK'] #may use junk in autoregressive generation (We add an extra 'JUNK' just in case the model ever emits something it shouldn’t)\n",
        "\n",
        "token_to_id = {tok: i for i, tok in enumerate(VOCAB)} # map each string token → integer index\n",
        "id_to_token = {i: tok for tok, i in token_to_id.items()} # invert that, for decoding model outputs back to strings\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "PAD_ID = token_to_id['PAD']\n",
        "EOS_ID = token_to_id['EOS']\n",
        "SOS_ID = token_to_id['SOS']\n",
        "\n",
        "MAX_DEPTH = 3 # MAX_DEPTH is the maximum recursion depth of our randomly generated expression trees\n",
        "MAX_LEN = 4*2**MAX_DEPTH -2 #enough to fit expressions at given depth (+ EOS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-fO911d6_FW"
      },
      "outputs": [],
      "source": [
        "# -------------------- Expression Generation --------------------\n",
        "\n",
        "# to produce a random fully-parenthesized infix string of maximum nesting depth max_depth\n",
        "def generate_infix_expression(max_depth):\n",
        "    if max_depth == 0: # (Base case) Once max_depth hits zero we stop recursing and return a single identifier\n",
        "        return random.choice(IDENTIFIERS)\n",
        "    elif random.random() < 0.5: # some branches will be shallower than the maximum depth (this contrivance vouches for a nice melting pot of small and large subtrees)\n",
        "        return generate_infix_expression(max_depth - 1)\n",
        "    else:\n",
        "        left = generate_infix_expression(max_depth - 1)\n",
        "        right = generate_infix_expression(max_depth - 1)\n",
        "        op = random.choice(OPERATORS)\n",
        "        return f'({left} {op} {right})' # wrap the two sub-strings and the operator\n",
        "\n",
        "def tokenize(expr):\n",
        "    return [c for c in expr if c in token_to_id] # filters symbols our model actually knows\n",
        "\n",
        "def infix_to_postfix(tokens):\n",
        "    precedence = {'+': 1, '-': 1, '*': 2, '/': 2}\n",
        "    output, stack = [], [] # output: the list we’ll build up with identifiers and operators in postfix order, stack let's say is a temporary stack for operators and parentheses ensuring correct ordering\n",
        "    for token in tokens:\n",
        "        if token in IDENTIFIERS: # put the identifier forthwith into the output\n",
        "            output.append(token)\n",
        "        elif token in OPERATORS: # if it's an operator (+-*/)\n",
        "            while stack and stack[-1] in OPERATORS and precedence[stack[-1]] >= precedence[token]:\n",
        "                output.append(stack.pop())\n",
        "            stack.append(token)\n",
        "        elif token == '(': # left parenthesis (\n",
        "            stack.append(token)\n",
        "        elif token == ')': # right parenthesis )\n",
        "            while stack and stack[-1] != '(':\n",
        "                output.append(stack.pop())\n",
        "            stack.pop()\n",
        "    while stack: # drain the stack for any operators left belong at the end of the expression\n",
        "        output.append(stack.pop())\n",
        "    return output\n",
        "\n",
        "def encode(tokens, max_len=MAX_LEN): # Converts each symbol in our token list into its integer index via the token_to_id dictionary, appends the special “End-Of-Sequence” token ID,\n",
        "                                     # eomputes how many padding slots we need so every sequence becomes exactly max_len long, extends our sequence with that many PAD tokens\n",
        "    ids = [token_to_id[t] for t in tokens] + [EOS_ID]\n",
        "    return ids + [PAD_ID] * (max_len - len(ids))\n",
        "\n",
        "def decode_sequence(token_ids, id_to_token=id_to_token, pad_token='PAD', eos_token='EOS'):\n",
        "\n",
        "    tokens = []\n",
        "    for token_id in token_ids:\n",
        "        token = id_to_token.get(token_id, '?')\n",
        "        if token == eos_token:\n",
        "            break\n",
        "        if token != pad_token:\n",
        "            tokens.append(token)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def generate_dataset(n,max_depth=MAX_DEPTH):\n",
        "    X, Y = [], []\n",
        "    for _ in range(n):\n",
        "        expr = generate_infix_expression(MAX_DEPTH)\n",
        "        #expr = expr_gen.generate(max_depth=max_dthep)\n",
        "        infix = tokenize(expr)\n",
        "        postfix = infix_to_postfix(infix)\n",
        "        X.append(encode(infix))\n",
        "        Y.append(encode(postfix))\n",
        "    return np.array(X), np.array(Y) # X is a batch of infix-encoded inputs, Y is the corresponding true postfix-encoded targets\n",
        "def data_generator(batch_size=128):\n",
        "    while True:\n",
        "        X, Y = generate_dataset(batch_size)\n",
        "        yield {\"infix_in\":X, \"post_in\":shift_right(Y)}, Y\n",
        "#we use the shift function for teacher-forcing\n",
        "def shift_right(seqs): # seq is the target Y\n",
        "    shifted = np.zeros_like(seqs)\n",
        "    shifted[:, 1:] = seqs[:, :-1]\n",
        "    shifted[:, 0] = SOS_ID # here we prepend the “Start-Of-Sequence” marker at time-step 0 for every sample\n",
        "    return shifted"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_infix_expression(d):\n",
        "    if d==0 or random.random()<0.5:\n",
        "        return random.choice(IDENTIFIERS)\n",
        "    L = generate_infix_expression(d-1)\n",
        "    R = generate_infix_expression(d-1)\n",
        "    return f'({L}{random.choice(OPERATORS)}{R})'\n",
        "\n",
        "def tokenize(expr):\n",
        "    return [c for c in expr if c in token_to_id]\n",
        "\n",
        "def infix_to_postfix(tokens):\n",
        "    prec, out, st = {'+':1,'-':1,'*':2,'/':2}, [], []\n",
        "    for t in tokens:\n",
        "        if t in IDENTIFIERS:\n",
        "            out.append(t)\n",
        "        elif t in OPERATORS:\n",
        "            while st and st[-1] in OPERATORS and prec[st[-1]]>=prec[t]:\n",
        "                out.append(st.pop())\n",
        "            st.append(t)\n",
        "        elif t=='(':\n",
        "            st.append(t)\n",
        "        else:\n",
        "            while st[-1]!='(':\n",
        "                out.append(st.pop())\n",
        "            st.pop()\n",
        "    while st:\n",
        "        out.append(st.pop())\n",
        "    return out\n",
        "\n",
        "def encode(tokens):\n",
        "    ids = [token_to_id[t] for t in tokens] + [EOS_ID]\n",
        "    return ids + [PAD_ID]*(MAX_LEN - len(ids))\n",
        "\n",
        "def decode(ids):\n",
        "    toks = []\n",
        "    for i in ids:\n",
        "        t = id_to_token[i]\n",
        "        if t=='EOS': break\n",
        "        if t!='PAD': toks.append(t)\n",
        "    return ' '.join(toks)\n",
        "\n",
        "def generate_dataset(n):\n",
        "    X, Y = [], []\n",
        "    for _ in range(n):\n",
        "        infix = tokenize(generate_infix_expression(MAX_DEPTH))\n",
        "        post  = infix_to_postfix(infix)\n",
        "        X.append(encode(infix))\n",
        "        Y.append(encode(post))\n",
        "    return np.array(X, dtype=np.int32), np.array(Y, dtype=np.int32)\n",
        "\n",
        "def shift_right(y):\n",
        "    out = np.zeros_like(y)\n",
        "    out[:,1:] = y[:,:-1]\n",
        "    out[:,0]  = SOS_ID\n",
        "    return out"
      ],
      "metadata": {
        "id": "KMxGhE-tEp9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DENVmP3Jq5Zf"
      },
      "source": [
        "Let us define a simple dataset, and inspect a few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdlonKn47dE7"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = generate_dataset(10000)\n",
        "decoder_input_train = shift_right(Y_train)\n",
        "\n",
        "# Dataset\n",
        "X_val, Y_val = generate_dataset(1000)\n",
        "decoder_input_val = shift_right(Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TogClrT6F2Th",
        "outputId": "2c51a8f1-fd7b-45a7-b375-b421309a43e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3663\n",
            "infix : ( ( b / a ) / ( ( b * b ) / ( b - e ) ) )\n",
            "postfix notation: b a / b b * b e - / /\n",
            "teacher forcing : SOS b a / b b * b e - / /\n"
          ]
        }
      ],
      "source": [
        "i =  np.random.randint(10000)\n",
        "print(i)\n",
        "\n",
        "print(\"infix :\", decode_sequence(X_train[i]))\n",
        "print(\"postfix notation:\", decode_sequence(Y_train[i]))\n",
        "print(\"teacher forcing :\", decode_sequence(decoder_input_train[i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWNlMURl1wzv"
      },
      "source": [
        "# Transformer Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZt23TeO17qO"
      },
      "source": [
        "First and foremost, we need to turn integer token IDs into continuous vectors that also carry information about each token's position in the sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp4TQG7i_8C8"
      },
      "source": [
        "Here we carry out class PositionEmbedding destined to combine embedding with positional settings.\n",
        "**token_emb**: modifies each input token into numerical continuous vectors.\n",
        "**position_emb**: this sort of embedding learns positional vectors, which encode information about the location of each token within the sequence. T put it in layman's terms, here we simply learn postional representations directly from data.\n",
        "\n",
        "**!!!**: Vitally important it is to factor in position_emb as further applied transformer appears to be susceptible to order - no intrinsic sense of order, so to speak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAZYTRw90ruH"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "  def __init__(self, max_len, dimensionality):\n",
        "      super().__init__()\n",
        "      # converts each discrete token ID into a learnt continuous vector of size dimensionality\n",
        "      self.token_emb = layers.Embedding(VOCAB_SIZE, dimensionality)\n",
        "      # same yet for positions instead of words\n",
        "      self.position_emb = layers.Embedding(max_len, dimensionality)\n",
        "  def call(self, x):\n",
        "    # further on we rely upon dynamic shapes ([0] would be the batch size and [1] is the sequence length)\n",
        "    length = tf.shape(x)[1]\n",
        "    # “input IDs” for the positional embedding lookup\n",
        "    positions = tf.range(length)\n",
        "    return self.token_emb(x) + self.position_emb(positions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVDDZUr-CjWY"
      },
      "source": [
        "# TRANSFORMER MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjlYjreKCtul"
      },
      "source": [
        "We define our transformer within a function aptly named **build\\_model**. From the outset, we embed input sequences using custom positional embeddings to effectively encode positional context alongside token information. Thoughtfully, we've integrated dropout and L2 regularisation across both embedding layers and intermediate layers aiming to boost generalisation and reduce the likelihood of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB2eTvfuGcg6"
      },
      "source": [
        "***Input parameters:***\n",
        "\n",
        "`maxlen` signifies the maximum sequence length the model handles ( it is needed for positional embeddings)\n",
        "\n",
        "`d_model` is the embedding dimension size\n",
        "\n",
        "`num_heads` is the number of attention heads (enables parallel attention to different feature spaces)\n",
        "\n",
        "`d_ff` alludes to the dimension of the Feed-Forward Network (FFN)\n",
        "\n",
        "`num_layers_enc`, `num_layers_dec` set the depth of encoder and decoder stacks.\n",
        "\n",
        "`dropout_rate` serves as regularisation (randomly drops neuron activations to forestall overfitting)\n",
        "\n",
        "`l2_reg` function as an L2 regularisation penalty to the kernel weights to encourage smaller weights to level uop generalisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH2Dzxfc6k-r"
      },
      "outputs": [],
      "source": [
        "def build_model(\n",
        "    maxlen=MAX_LEN, d_model=128,\n",
        "    num_heads=6, d_ff=512,\n",
        "    num_layers_enc=3, num_layers_dec=3,\n",
        "    dropout_rate=0.15, l2_reg=1e-6\n",
        "):\n",
        "    infix_in = layers.Input((maxlen,), name=\"infix_in\")\n",
        "    post_in = layers.Input((maxlen,), name=\"post_in\")\n",
        "\n",
        "    # Embedding + Dropout part\n",
        "    # *** Here immediately to prevent the model from becoming overly reliant on specific token representations\n",
        "    enc_x = layers.Dropout(dropout_rate)(PositionalEmbedding(maxlen,d_model)(infix_in))\n",
        "    dec_x = layers.Dropout(dropout_rate)(PositionalEmbedding(maxlen,d_model)(post_in))\n",
        "\n",
        "    # ENCODER PART\n",
        "    # *** Here we push forward repeated identical layers\n",
        "    for i in range(num_layers_enc):\n",
        "\n",
        "        # Attentions here is set to capture so-called contextual relationships\n",
        "        attn = layers.MultiHeadAttention(num_heads,key_dim=d_model//num_heads,dropout=dropout_rate,kernel_regularizer=regularizers.l2(l2_reg))(enc_x, enc_x)\n",
        "        attn = layers.Dropout(dropout_rate)(attn)\n",
        "\n",
        "        # Normalisation serves for residual connection (enc_x + attn) maintenance of gradient flow. To put it differently, Normalisation helps in stabilising the distribution on the output\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(enc_x + attn)\n",
        "\n",
        "        # Two-layer dense structure (Expands (d_ff) whereupon these layers compresses (d_model) the representation).\n",
        "        # Relu introduces non-linearity necessary for capturing more complex patterns\n",
        "        ffn = layers.Dense(d_ff, activation='relu',kernel_regularizer=regularizers.l2(l2_reg))(x1)\n",
        "        ffn = layers.Dropout(dropout_rate)(ffn)\n",
        "        ffn = layers.Dense(d_model,kernel_regularizer=regularizers.l2(l2_reg))(ffn)\n",
        "        enc_x = layers.LayerNormalization(epsilon=1e-6)(x1 + ffn)\n",
        "\n",
        "    # DECODER PART\n",
        "    for j in range(num_layers_dec):\n",
        "        # A custom Lambda layer constructs a causal mask to ensure each position in the sequence can only attend to previous positions\n",
        "        # preventing leakage of future information during training\n",
        "\n",
        "        # CAUSAL MASKING IS ESSENTIAL FOR AUTOREGRESSIVE MOOD OF GENERATION!!\n",
        "        def causal_mask(x):\n",
        "            b = tf.shape(x)[0]; s = tf.shape(x)[1] # dynamically adapts to input sequences of varying batch sizes and lengths\n",
        "            m = tf.linalg.band_part(tf.ones((s,s)),-1,0)\n",
        "            return tf.tile(m[None], [b,1,1])\n",
        "        mask = layers.Lambda(causal_mask)(dec_x)\n",
        "\n",
        "        # Decoder's self-attention\n",
        "        # *** Ensures each token prediction only uses previously known tokens\n",
        "        att1 = layers.MultiHeadAttention(num_heads,key_dim=d_model//num_heads,dropout=dropout_rate,kernel_regularizer=regularizers.l2(l2_reg))(dec_x, dec_x, attention_mask=mask)\n",
        "        att1 = layers.Dropout(dropout_rate)(att1)\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(dec_x + att1)\n",
        "\n",
        "        # Cross-attention (Decoder-to-Encoder)\n",
        "        # *** Allows the decoder to access and attend to the encoder’s output\n",
        "        att2 = layers.MultiHeadAttention(num_heads,key_dim=d_model//num_heads,dropout=dropout_rate,kernel_regularizer=regularizers.l2(l2_reg))(x1, enc_x)\n",
        "        att2 = layers.Dropout(dropout_rate)(att2)\n",
        "        x2 = layers.LayerNormalization(epsilon=1e-6)(x1 + att2)\n",
        "\n",
        "        # -||- (for x2)\n",
        "        ffn = layers.Dense(d_ff, activation='relu',kernel_regularizer=regularizers.l2(l2_reg))(x2)\n",
        "        ffn = layers.Dropout(dropout_rate)(ffn)\n",
        "        ffn = layers.Dense(d_model,kernel_regularizer=regularizers.l2(l2_reg))(ffn)\n",
        "        dec_x = layers.LayerNormalization(epsilon=1e-6)(x2 + ffn)\n",
        "\n",
        "    logits = layers.Dense(len(VOCAB), name=\"final_proj\")(dec_x) # These logits reflect how strongly the model believes each vocabulary token is likely at each position in the output sequence\n",
        "    return Model([infix_in, post_in], logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoregressive data generation\n",
        "A model is autoregressive when it generates a sequence one token at a time, each time conditioning on all the tokens it has already produced"
      ],
      "metadata": {
        "id": "Ag3Nl3wf66Jc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbPlczMP6pbf"
      },
      "outputs": [],
      "source": [
        "# Greedy Decoding\n",
        "# we input one fully tokenised infix expression (of shape MAX_LEN)\n",
        "# output is a postfix expression predicted by the model (so let's say if i had [3,2,10,4,...] it turns to [\"a b +\"...])\n",
        "def greedy_decode(model, x_seq, max_len=MAX_LEN):\n",
        "\n",
        "    x_seq = x_seq[None]                  # (1, seq) is a batch dimension\n",
        "    out   = []                           # previous prediction storage (generated token-ids)\n",
        "\n",
        "    for step in range(max_len - 1):      # we also need '-1' here to allocate some room for the end of the string indicator\n",
        "        dec_in = np.array([SOS_ID] + out + [PAD_ID]*(max_len-1-len(out)))[None] # also granted we need to align the lenght i add PAD (used to pad every sequence to a fixed length)\n",
        "        # FORWARD PASS\n",
        "        # the encoder sees the whole infix expression at once\n",
        "        # the decoder sees only the prefix via causal mask (causal mask is needed here since self-attention lets every position look at all other positions in the same sequence. Hence it can peek at what the model is predicting which is fundamentally wrong)\n",
        "        logits = model.predict(\n",
        "            {\"infix_in\": x_seq, \"post_in\": dec_in},\n",
        "            verbose=0\n",
        "        )\n",
        "        next_id = int(np.argmax(logits[0, len(out)]))   # GREEDY SEARCH\n",
        "\n",
        "        if next_id == EOS_ID: # END!\n",
        "            break\n",
        "        out.append(next_id)\n",
        "\n",
        "    return out\n",
        "\n",
        "# Metric\n",
        "\n",
        "loss_ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none') # goes about token-by-token instead of merely tracking the ordinary cross-entropy loss\n",
        "\n",
        "def loss_with_mask(y_true, y_pred):\n",
        "    mask = tf.cast(tf.not_equal(y_true, PAD_ID), tf.float32) # we compare every element of the ground-truth tensor with the constant PAD_ID. Eventually we deduce a tensor which contains \"True\" at positions that should be kept and False where the token is PAD\n",
        "    loss = loss_ce(y_true, y_pred) * mask # merging with the mask\n",
        "    return tf.reduce_sum(loss) / tf.reduce_sum(mask) # calculating mean over real tokens\n",
        "\n",
        "def prefix_acc_single(y_true_batch, y_pred_batch): # per a batch\n",
        "    accs = []\n",
        "    for y_t, y_p in zip(y_true_batch, y_pred_batch):\n",
        "        t = decode(y_t).split() # ground truth tokens\n",
        "        p = decode(y_p).split() # predicted tokens\n",
        "        m = max(len(t), len(p))\n",
        "        accs.append(sum(a == b for a, b in zip(t, p)) / m if m else 0)\n",
        "    return np.mean(accs).astype(\"float32\")\n",
        "\n",
        "\n",
        "def prefix_acc(y_true, y_pred):\n",
        "    y_pred_ids = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n",
        "    acc = tf.numpy_function(prefix_acc_single, [y_true, y_pred_ids],\n",
        "                            tf.float32)\n",
        "    acc.set_shape(())\n",
        "    return acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Test\n",
        "def test(model, no=20, rounds=10):\n",
        "    scores = []\n",
        "    for _ in range(rounds):\n",
        "        Xv, Yv = generate_dataset(no)\n",
        "        sc = [prefix_acc_single(y, greedy_decode(model,x))\n",
        "              for x,y in zip(Xv,Yv)]\n",
        "        scores.append(statistics.mean(sc))\n",
        "    return statistics.mean(scores), statistics.stdev(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training and Results**"
      ],
      "metadata": {
        "id": "oRyz3GnoE7oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train for up to 30 epochs turning to good account the following settings:\n",
        "\n",
        "- **Batch size:** 128  \n",
        "- **Steps per epoch:** 100  \n",
        "- **Optimizer:** AdamW(1e-3, weight_decay=1e-6)  \n",
        "- **Loss:** SparseCategoricalCrossentropy(from_logits=True)  \n",
        "- **Metrics:** token-level sparse categorical accuracy  \n",
        "- **Dropout:** 0.15 in attention & FFN sublayers (plus 0.15 after embeddings)  \n",
        "- **L2 weight decay:** 1e-6 on all projection kernels  \n",
        "- **EarlyStopping:** monitor val_accuracy, patience=3, restore best  \n",
        "- **ReduceLROnPlateau:** halve LR when val_accuracy stalls, min_lr=1e-6  \n",
        "\n",
        "Besides, in the course of the present we kick off training and capture the returned `history`\n",
        "\n",
        "In principle, 30 epochs were come down in favour of largely as an upper bound rather than because we expect the model to need that many passes. Exactly for the reason of optimising time consumption, EarlyStoppint was deployed in the model. FOrthwith upon stagnation in validation accuracy (stops improving for 3 epochs on the trot), the model's training halts. hence 30 is just a high ceiling."
      ],
      "metadata": {
        "id": "iYBKw4MeDMRc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VuwuffDh7OiB",
        "outputId": "983b4321-57ff-4111-b4e2-18520c3082a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ infix_in            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,760</span> │ infix_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_260         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,018</span> │ dropout_260[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ dropout_260[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_263         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_150 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_260[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ dropout_263[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_150[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_264         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_120[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout_264[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_121[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,018</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_266         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_266[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_267         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_122[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout_267[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_123[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,018</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ post_in             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_269         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,760</span> │ post_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_269[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_261         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_261[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,018</span> │ dropout_261[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ dropout_261[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ lambda_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_270         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_124[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_272         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout_270[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_261[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ dropout_272[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_125[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,018</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_274         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_274[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_157[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_275         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout_275[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_127[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_158[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,018</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "│                     │                   │            │ lambda_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_277         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_277[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_159[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,018</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_279         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_279[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_160[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_280         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout_280[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_161 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_161[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,018</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "│                     │                   │            │ lambda_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_282         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_282[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_162[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,018</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_284         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_284[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_163[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_285         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout_285[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_164[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ final_proj (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935</span> │ layer_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ infix_in            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m5,760\u001b[0m │ infix_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_260         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,018\u001b[0m │ dropout_260[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ dropout_260[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_263         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_150 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_260[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ dropout_263[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_150[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_120 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_264         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_120[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_121 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ dropout_264[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_151 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_121[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,018\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_266         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_152 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_266[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_122 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_267         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_122[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_123 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ dropout_267[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_153 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_123[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,018\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ post_in             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_269         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m5,760\u001b[0m │ post_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_154 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_269[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_261         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_30 (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_261[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_124 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,018\u001b[0m │ dropout_261[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ dropout_261[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ lambda_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_270         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_124[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_272         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_125 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ dropout_270[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_156 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_261[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ dropout_272[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_155 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_125[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,018\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_274         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_157 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_274[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_157[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_126 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_275         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_127 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ dropout_275[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_158 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_127[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_158[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_31 (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,018\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "│                     │                   │            │ lambda_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_277         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_159 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_277[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_159[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,018\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_279         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_160 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_279[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_160[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_128 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_280         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_129 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ dropout_280[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_161 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_161[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_32 (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,018\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "│                     │                   │            │ lambda_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_282         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_162 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_282[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_162[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,018\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_284         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_163 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_284[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_163[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_130 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_285         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_130[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_131 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ dropout_285[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_164 (\u001b[38;5;33mAdd\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_164[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ final_proj (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m15\u001b[0m)    │      \u001b[38;5;34m1,935\u001b[0m │ layer_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,392,729</span> (5.31 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,392,729\u001b[0m (5.31 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,392,729</span> (5.31 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,392,729\u001b[0m (5.31 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 - 293s - 3s/step - loss: 1.3540 - prefix_acc: 0.5626 - tok_acc: 0.0805 - val_loss: 0.6542 - val_prefix_acc: 0.8540 - val_tok_acc: 0.1244 - learning_rate: 1.0000e-03\n",
            "Epoch 2/10\n",
            "100/100 - 258s - 3s/step - loss: 0.4461 - prefix_acc: 0.9076 - tok_acc: 0.1389 - val_loss: 0.1071 - val_prefix_acc: 0.9799 - val_tok_acc: 0.1616 - learning_rate: 1.0000e-03\n",
            "Epoch 3/10\n",
            "100/100 - 272s - 3s/step - loss: 0.0979 - prefix_acc: 0.9821 - tok_acc: 0.1601 - val_loss: 0.0228 - val_prefix_acc: 0.9973 - val_tok_acc: 0.1668 - learning_rate: 1.0000e-03\n",
            "Epoch 4/10\n",
            "100/100 - 257s - 3s/step - loss: 0.0418 - prefix_acc: 0.9929 - tok_acc: 0.1648 - val_loss: 0.0309 - val_prefix_acc: 0.9934 - val_tok_acc: 0.1664 - learning_rate: 1.0000e-03\n",
            "Epoch 5/10\n",
            "100/100 - 244s - 2s/step - loss: 0.0210 - prefix_acc: 0.9967 - tok_acc: 0.1668 - val_loss: 0.0090 - val_prefix_acc: 0.9986 - val_tok_acc: 0.1674 - learning_rate: 5.0000e-04\n",
            "Epoch 6/10\n",
            "100/100 - 254s - 3s/step - loss: 0.0144 - prefix_acc: 0.9979 - tok_acc: 0.1652 - val_loss: 0.0096 - val_prefix_acc: 0.9986 - val_tok_acc: 0.1674 - learning_rate: 5.0000e-04\n",
            "Epoch 7/10\n",
            "100/100 - 257s - 3s/step - loss: 0.0116 - prefix_acc: 0.9983 - tok_acc: 0.1645 - val_loss: 0.0075 - val_prefix_acc: 0.9989 - val_tok_acc: 0.1675 - learning_rate: 2.5000e-04\n",
            "Epoch 8/10\n",
            "100/100 - 246s - 2s/step - loss: 0.0098 - prefix_acc: 0.9987 - tok_acc: 0.1669 - val_loss: 0.0067 - val_prefix_acc: 0.9993 - val_tok_acc: 0.1676 - learning_rate: 2.5000e-04\n",
            "Epoch 9/10\n",
            "100/100 - 248s - 2s/step - loss: 0.0088 - prefix_acc: 0.9990 - tok_acc: 0.1662 - val_loss: 0.0053 - val_prefix_acc: 0.9999 - val_tok_acc: 0.1678 - learning_rate: 2.5000e-04\n",
            "Epoch 10/10\n",
            "100/100 - 247s - 2s/step - loss: 0.0079 - prefix_acc: 0.9993 - tok_acc: 0.1665 - val_loss: 0.0053 - val_prefix_acc: 0.9995 - val_tok_acc: 0.1677 - learning_rate: 2.5000e-04\n",
            "\n",
            "Prefix-accuracy on 20 fresh samples:  1.000 ± 0.000\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    tf.keras.utils.set_random_seed(0)\n",
        "\n",
        "    model = build_model()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "        loss=loss_with_mask,\n",
        "        metrics=[\n",
        "            tf.keras.metrics.SparseCategoricalAccuracy(name=\"tok_acc\"),\n",
        "            prefix_acc\n",
        "        ]\n",
        "    )\n",
        "    model.summary()\n",
        "    # ─── validation set ───\n",
        "    X_val, Y_val   = generate_dataset(2000)\n",
        "    post_val_shift = shift_right(Y_val)\n",
        "\n",
        "    # ─── training generator (Keras expects *a generator*, not a function) ───\n",
        "    def train_gen(batch_size=128):\n",
        "        while True:\n",
        "            X, Y = generate_dataset(batch_size)\n",
        "            yield {\"infix_in\": X,\n",
        "                   \"post_in\":  shift_right(Y)}, Y\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor=\"val_tok_acc\", patience=2, mode=\"max\",\n",
        "                      restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_tok_acc\", factor=0.5,\n",
        "                          patience=1, mode=\"max\", min_lr=1e-5)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen(128),\n",
        "        steps_per_epoch=100,\n",
        "        epochs=10,\n",
        "        validation_data=({\"infix_in\": X_val,\n",
        "                          \"post_in\":  post_val_shift}, Y_val),\n",
        "        callbacks=callbacks,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    # ─── quick sanity-check ───\n",
        "    # X_test, Y_test = make_dataset(20)\n",
        "    # preds  = [greedy_decode(model, x) for x in X_test]\n",
        "    # scores = [prefix_acc_single(y, p) for y, p in zip(Y_test, preds)]\n",
        "    # print(f\"\\nPrefix-accuracy on 20 fresh samples: \"\n",
        "    #       f\"{np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
        "\n",
        "    X_test, Y_test = generate_dataset(20)\n",
        "    pairings = [decode(Y_test[i]) == decode(greedy_decode(model, X_test[i])) for i in range(20)]\n",
        "    print(f\"\\nPrefix-accuracy on 20 fresh samples: \", f\"{np.mean(pairings):.3f} ± {np.std(pairings):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training and validation loss curves**"
      ],
      "metadata": {
        "id": "UYwdikq4G8Fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss"
      ],
      "metadata": {
        "id": "JEdLTwcoHULZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Lossses')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "BvFczYZDGmba",
        "outputId": "356818f5-9456-4a6f-dcc0-73581cb17339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy"
      ],
      "metadata": {
        "id": "FH2H9WeuHYJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['tok_acc'],      label='train tok_acc')\n",
        "plt.plot(history.history['val_tok_acc'],  label='val tok_acc')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "yZcYjJysHOAS",
        "outputId": "58e70b45-e72e-4d7b-9924-519e4337b55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgqDkVaztBuv"
      },
      "source": [
        "# Constraints\n",
        "* You may use any architecture (decoder-only, encoder-decoder, or other).\n",
        "\n",
        "* The maximum number of parameters is 2 million.\n",
        "\n",
        "* Beam search is not allowed.\n",
        "\n",
        "* You may adapt the formula generator to your needs, but preserve its core logic—especially the frequency distribution of formulas by depth, as it may significantly influence model performance.\n",
        "\n",
        "* You may train your model using a pre-generated fixed dataset (e.g., an array) or directly use an on-the-fly generator.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDUjK4SGvT0s"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We shall evaluate a generated item y_pred using \"prefix accuracy\", the lenght of\n",
        "the initial prefix of y_pred matching the ground true y_true. This will be divided by the maximum length of y_true and y_pred (up to EOS), so that a perfect match has score 1.\n",
        "\n",
        "* It's more informative than exact match (which is often 0)\n",
        "\n",
        "* It’s tighter than edit distance: focuses on generation flow\n",
        "\n",
        "* Captures where the model starts to make errors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeCRiqvsxQax"
      },
      "source": [
        "For the exam, evaluate you model on a test set of 20 expressions. Repeat this evaluation 10 times, and return the mean and std for this rounds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxxXPqKQ86fZ"
      },
      "source": [
        "Be sure to evalutate the generator: your model may only take as input the expression in infix format and return its translation to postifix.\n",
        "\n",
        "If you are usuing an encoder-decoder model, generation must be done autoregressively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOBottQI9o1h"
      },
      "source": [
        "# What to deliver\n",
        "\n",
        "As usual you are supposed to deliver a single notebook witten in Keras. You are auhtorized to use Keras3 with pytorch as backend if your prefer.\n",
        "\n",
        "Do no upload a zip file: the submission will be rejected.\n",
        "\n",
        "The python notebook should have a clear documentation of the training phase, possibly with its history.\n",
        "\n",
        "You should be able to provide the network paramters upon request. Even better, consider a way to upload them inside your notebook using gdown."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}